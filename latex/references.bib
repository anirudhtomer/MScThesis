
@article{fruhwirth-schnatter_bayesian_2004,
	title = {Bayesian {Analysis} of the {Heterogeneity} {Model}},
	volume = {22},
	issn = {0735-0015},
	url = {http://dx.doi.org/10.1198/073500103288619331},
	doi = {10.1198/073500103288619331},
	abstract = {We consider Bayesian estimation of a finite mixture of models with random effects, which is also known as the heterogeneity model. First, we discuss the properties of various Markov chain Monte Carlo samplers that are obtained from full conditional Gibbs sampling by grouping and collapsing. Whereas full conditional Gibbs sampling turns out to be sensitive to the parameterization chosen for the mean structure of the model, the alternative sampler is robust in this respect. However, the logical extension of the approach to the sampling of the group variances does not further increase the efficiency of the sampler. Second, we deal with the identifiability problem due to the arbitrary labeling within the model. Finally, a case study involving metric conjoint analysis serves as a practical illustration.},
	number = {1},
	urldate = {2015-10-13},
	journal = {Journal of Business \& Economic Statistics},
	author = {Frühwirth-Schnatter, Sylvia and Tüchler, Regina and Otter, Thomas},
	month = jan,
	year = {2004},
	pages = {2--15},
	file = {Full Text PDF:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\A9BI2E9B\\Frühwirth-Schnatter et al. - 2004 - Bayesian Analysis of the Heterogeneity Model.pdf:application/pdf;Snapshot:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\H8V4XZ3Q\\073500103288619331.html:text/html}
}

@book{_mixtures:_2011,
	address = {Hoboken, N.J},
	edition = {1 edition},
	title = {Mixtures: {Estimation} and {Applications}},
	isbn = {978-1-119-99389-6},
	shorttitle = {Mixtures},
	language = {English},
	publisher = {Wiley},
	month = jun,
	year = {2011}
}

@article{celeux_deviance_2006,
	title = {Deviance information criteria for missing data models},
	volume = {1},
	issn = {1936-0975, 1931-6690},
	url = {http://projecteuclid.org/euclid.ba/1340370933},
	doi = {10.1214/06-BA122},
	abstract = {The deviance information criterion (DIC) introduced by Spiegelhalter et al.(2002) for model assessment and model comparison is directly inspired by linear and generalised linear models, but it is open to different possible variations in the setting of missing data models, depending in particular on whether or not the missing variables are treated as parameters. In this paper, we reassess the criterion for such models and compare different DIC constructions, testing the behaviour of these various extensions in the cases of mixtures of distributions and random effect models.},
	language = {EN},
	number = {4},
	urldate = {2016-04-30},
	journal = {Bayesian Analysis},
	author = {Celeux, G. and Forbes, F. and Robert, C. P. and Titterington, D. M.},
	month = dec,
	year = {2006},
	mrnumber = {MR2282197},
	keywords = {completion, deviance, DIC, EM algorithm, MAP, Mixture model, model comparison, random effect model},
	pages = {651--673},
	file = {Snapshot:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\A85QBS6J\\1340370933.html:text/html}
}

@book{verbeke_linear_2009,
	title = {Linear {Mixed} {Models} for {Longitudinal} {Data}},
	isbn = {978-1-4419-0299-3},
	abstract = {This book provides a comprehensive treatment of linear mixed models for continuous longitudinal data. Next to model formulation, this edition puts major emphasis on exploratory data analysis for all aspects of the model, such as the marginal model, subject-specific profiles, and residual covariance structure. Further, model diagnostics and missing data receive extensive treatment. Sensitivity analysis for incomplete data is given a prominent place. Several variations to the conventional linear mixed model are discussed (a heterogeity model, conditional linear mid models). This book will be of interest to applied statisticians and biomedical researchers in industry, public health organizations, contract research organizations, and academia. The book is explanatory rather than mathematically rigorous. Most analyses were done with the MIXED procedure of the SAS software package, and many of its features are clearly elucidated. How3ever, some other commercially available packages are discussed as well. Great care has been taken in presenting the data analyses in a software-independent fashion. Geert Verbeke is Assistant Professor at the Biostistical Centre of the Katholieke Universiteit Leuven in Belgium. He received the B.S. degree in mathematics (1989) from the Katholieke Universiteit Leuven, the M.S. in biostatistics (1992) from the Limburgs Universitair Centrum, and earned a Ph.D. in biostatistics (1995) from the Katholieke Universiteit Leuven. Dr. Verbeke wrote his dissertation, as well as a number of methodological articles, on various aspects of linear mixed models for longitudinal data analysis. He has held visiting positions at the Gerontology Research Center and the Johns Hopkins University. Geert Molenberghs is Assistant Professor of Biostatistics at the Limburgs Universitair Centrum in Belgium. He received the B.S. degree in mathematics (1988) and a Ph.D. in biostatistics (1993) from the Universiteit Antwerpen. Dr. Molenberghs published methodological work on the analysis of non-response in clinical and epidemiological studies. He serves as an associate editor for Biometrics, Applied Statistics, and Biostatistics, and is an officer of the Belgian Statistical Society. He has held visiting positions at the Harvard School of Public Health.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Verbeke, Geert and Molenberghs, Geert},
	month = apr,
	year = {2009},
	keywords = {Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes}
}

@book{gelman_bayesian_2013,
	title = {Bayesian {Data} {Analysis}, {Third} {Edition}},
	isbn = {978-1-4398-4095-5},
	abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors—all leaders in the statistics community—introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition   Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code   The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book’s web page.},
	language = {en},
	publisher = {CRC Press},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
	month = nov,
	year = {2013},
	keywords = {Computers / Mathematical \& Statistical Software, Mathematics / Probability \& Statistics / General, Psychology / Research \& Methodology}
}

@article{gianola_mixture_2007,
	title = {Mixture models in quantitative genetics and applications to animal breeding},
	volume = {36},
	issn = {1516-3598},
	url = {http://www.scielo.br/scielo.php?script=sci_abstract&pid=S1516-35982007001000017&lng=en&nrm=iso&tlng=en},
	doi = {10.1590/S1516-35982007001000017},
	urldate = {2015-10-11},
	journal = {Revista Brasileira de Zootecnia},
	author = {Gianola, Daniel and Boettcher, Paul J. and Ødegård, Jørgen and Heringstad, Bjørg},
	month = jul,
	year = {2007},
	pages = {172--183},
	file = {Full Text PDF:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\SHNR29EJ\\Gianola et al. - 2007 - Mixture models in quantitative genetics and applic.pdf:application/pdf;Snapshot:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\QBCKHM6M\\scielo.html:text/html}
}

@article{gelfand_efficient_1995,
	title = {Efficient {Parametrisations} for {Normal} {Linear} {Mixed} {Models}},
	volume = {82},
	copyright = {Copyright © 1995 Biometrika Trust},
	issn = {0006-3444},
	url = {http://www.jstor.org.kuleuven.ezproxy.kuleuven.be/stable/2337527},
	doi = {10.2307/2337527},
	abstract = {The generality and easy programmability of modern sampling-based methods for maximisation of likelihoods and summarisation of posterior distributions have led to a tremendous increase in the complexity and dimensionality of the statistical models used in practice. However, these methods can often be extremely slow to converge, due to high correlations between, or weak identifiability of, certain model parameters. We present simple hierarchical centring reparametrisations that often give improved convergence for a broad class of normal linear mixed models. In particular, we study the two-stage hierarchical normal linear models, the Laird-Ware model for longitudinal data, and a general structure for hierarchically nested linear models. Using analytical arguments, simulation studies, and an example involving clinical markers of acquired immune deficiency syndrome (AIDS), we indicate when reparametrisation is likely to provide substantial gains in efficiency.},
	number = {3},
	urldate = {2015-10-13},
	journal = {Biometrika},
	author = {Gelfand, Alan E. and Sahu, Sujit K. and Carlin, Bradley P.},
	month = sep,
	year = {1995},
	pages = {479--488},
	file = {JSTOR Full Text PDF:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\G2UUMFDN\\Gelfand et al. - 1995 - Efficient Parametrisations for Normal Linear Mixed.pdf:application/pdf}
}

@article{johannes_berkhof_bayesian_2003,
	title = {A {Bayesian} approach to the selection and testing of mixture models},
	volume = {13},
	issn = {1017-0405},
	number = {2},
	journal = {Statistica Sinica},
	author = {Johannes Berkhof, Iven Van Mechelen},
	year = {2003},
	pages = {423--442},
	file = {A Bayesian approach to the selection and testing of mixture models:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\399K8UJF\\228816555_A_Bayesian_approach_to_the_selection_and_testing_of_mixture_models.html:text/html}
}

@article{xiang_efficient_2003,
	title = {Efficient text-independent speaker verification with structural {Gaussian} mixture models and neural network},
	volume = {11},
	issn = {1063-6676},
	doi = {10.1109/TSA.2003.815822},
	abstract = {We present an integrated system with structural Gaussian mixture models (SGMMs) and a neural network for purposes of achieving both computational efficiency and high accuracy in text-independent speaker verification. A structural background model (SBM) is constructed first by hierarchically clustering all Gaussian mixture components in a universal background model (UBM). In this way the acoustic space is partitioned into multiple regions in different levels of resolution. For each target speaker, a SGMM can be generated through multilevel maximum a posteriori (MAP) adaptation from the SBM. During test, only a small subset of Gaussian mixture components are scored for each feature vector in order to reduce the computational cost significantly. Furthermore, the scores obtained in different layers of the tree-structured models are combined via a neural network for final decision. Different configurations are compared in the experiments conducted on the telephony speech data used in the NIST speaker verification evaluation. The experimental results show that computational reduction by a factor of 17 can be achieved with 5\% relative reduction in equal error rate (EER) compared with the baseline. The SGMM-SBM also shows some advantages over the recently proposed hash GMM, including higher speed and better verification performance.},
	number = {5},
	journal = {IEEE Transactions on Speech and Audio Processing},
	author = {Xiang, Bing and Berger, T.},
	month = sep,
	year = {2003},
	keywords = {acoustic space partitioning, Acoustic testing, computational complexity, computational cost reduction, computational efficiency, efficient text-independent speaker verification, equal error rate reduction, Error analysis, feature vector, Gaussian mixture components, Gaussian mixture models, Gaussian processes, hash GMM, Hidden Markov models, integrated system, Loudspeakers, multilevel MAP adaptation, multilevel maximum a posteriori adaptation, neural nets, neural network, Neural networks, NIST, NIST speaker verification evaluation, speaker recognition, speaker verification performance, Speech analysis, structural background model, telephony, telephony speech data, text-independent speaker verification, tree data structures, tree-structured models, universal background model},
	pages = {447--456},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\Q6DZU4T4\\abs_all.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\6KUB7A8D\\Xiang and Berger - 2003 - Efficient text-independent speaker verification wi.pdf:application/pdf}
}

@article{chib_marginal_1995,
	title = {Marginal {Likelihood} from the {Gibbs} {Output}},
	volume = {90},
	issn = {0162-1459},
	url = {http://www.jstor.org.kuleuven.ezproxy.kuleuven.be/stable/2291521},
	doi = {10.2307/2291521},
	abstract = {In the context of Bayes estimation via Gibbs sampling, with or without data augmentation, a simple approach is developed for computing the marginal density of the sample data (marginal likelihood) given parameter draws from the posterior distribution. Consequently, Bayes factors for model comparisons can be routinely computed as a by-product of the simulation. Hitherto, this calculation has proved extremely challenging. Our approach exploits the fact that the marginal density can be expressed as the prior times the likelihood function over the posterior density. This simple identity holds for any parameter value. An estimate of the posterior density is shown to be available if all complete conditional densities used in the Gibbs sampler have closed-form expressions. To improve accuracy, the posterior density is estimated at a high density point, and the numerical standard error of resulting estimate is derived. The ideas are applied to probit regression and finite mixture models.},
	number = {432},
	urldate = {2016-04-30},
	journal = {Journal of the American Statistical Association},
	author = {Chib, Siddhartha},
	year = {1995},
	pages = {1313--1321}
}

@article{stephens_dealing_2000,
	title = {Dealing with label switching in mixture models},
	volume = {62},
	copyright = {2000 Royal Statistical Society},
	issn = {1467-9868},
	url = {http://onlinelibrary.wiley.com.kuleuven.ezproxy.kuleuven.be/doi/10.1111/1467-9868.00265/abstract},
	doi = {10.1111/1467-9868.00265},
	abstract = {In a Bayesian analysis of finite mixture models, parameter estimation and clustering are sometimes less straightforward than might be expected. In particular, the common practice of estimating parameters by their posterior mean, and summarizing joint posterior distributions by marginal distributions, often leads to nonsensical answers. This is due to the so-called ‘label switching’ problem, which is caused by symmetry in the likelihood of the model parameters. A frequent response to this problem is to remove the symmetry by using artificial identifiability constraints. We demonstrate that this fails in general to solve the problem, and we describe an alternative class of approaches, relabelling algorithms, which arise from attempting to minimize the posterior expected loss under a class of loss functions. We describe in detail one particularly simple and general relabelling algorithm and illustrate its success in dealing with the label switching problem on two examples.},
	language = {en},
	number = {4},
	urldate = {2015-10-14},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Stephens, Matthew},
	month = jan,
	year = {2000},
	keywords = {Bayesian approach, Classification, Clustering, Identifiability, Markov chain Monte Carlo methods, Mixture model, Multimodal posterior},
	pages = {795--809},
	file = {Full Text PDF:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\TRCIXRMV\\Stephens - 2000 - Dealing with label switching in mixture models.pdf:application/pdf;Snapshot:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\4JTFUW82\\abstract.html:text/html}
}

@article{stephens_bayesian_2000,
	title = {Bayesian {Analysis} of {Mixture} {Models} with an {Unknown} {Number} of {Components}- {An} {Alternative} to {Reversible} {Jump} {Methods}},
	volume = {28},
	copyright = {Copyright © 2000 Institute of Mathematical Statistics},
	issn = {0090-5364},
	url = {http://www.jstor.org/stable/2673981},
	abstract = {Richardson and Green present a method of performing a Bayesian analysis of data from a finite mixture distribution with an unknown number of components. Their method is a Markov Chain Monte Carlo (MCMC) approach, which makes use of the "reversible jump" methodology described by Green. We describe an alternative MCMC method which views the parameters of the model as a (marked) point process, extending methods suggested by Ripley to create a Markov birth-death process with an appropriate stationary distribution. Our method is easy to implement, even in the case of data in more than one dimension, and we illustrate it on both univariate and bivariate data. There appears to be considerable potential for applying these ideas to other contexts, as an alternative to more general reversible jump methods, and we conclude with a brief discussion of how this might be achieved.},
	number = {1},
	urldate = {2015-10-15},
	journal = {The Annals of Statistics},
	author = {Stephens, Matthew},
	month = feb,
	year = {2000},
	pages = {40--74},
	file = {JSTOR Full Text PDF:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\BUWJ5ERN\\Stephens - 2000 - Bayesian Analysis of Mixture Models with an Unknow.pdf:application/pdf}
}

@article{verbeke_linear_1996,
	title = {A {Linear} {Mixed}-{Effects} {Model} {With} {Heterogeneity} in the {Random}-{Effects} {Population}},
	volume = {91},
	copyright = {Copyright © 1996 American Statistical Association},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2291398},
	abstract = {This article investigates the impact of the normality assumption for random effects on their estimates in the linear mixed-effects model. It shows that if the distribution of random effects is a finite mixture of normal distributions, then the random effects may be badly estimated if normality is assumed, and the current methods for inspecting the appropriateness of the model assumptions are not sound. Further, it is argued that a better way to detect the components of the mixture is to build this assumption in the model and then "compare" the fitted model with the Gaussian model. All of this is illustrated on two practical examples},
	number = {433},
	urldate = {2015-10-10},
	journal = {Journal of the American Statistical Association},
	author = {Verbeke, Geert and Lesaffre, Emmanuel},
	month = mar,
	year = {1996},
	pages = {217--221},
	file = {JSTOR Full Text PDF:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\ZTKKXX5R\\Verbeke and Lesaffre - 1996 - A Linear Mixed-Effects Model With Heterogeneity in.pdf:application/pdf}
}

@misc{_how_????,
	title = {How does function approximation in {Neural} network really works? - {Stack} {Overflow}},
	shorttitle = {How does function approximation in {Neural} network really works?},
	url = {http://stackoverflow.com/questions/ask},
	urldate = {2015-12-16},
	file = {Snapshot:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\6CSTXEVQ\\How does function approximation in Neural network .html:text/html}
}

@article{lewicki_bayesian_1994,
	title = {Bayesian {Modeling} and {Classification} of {Neural} {Signals}},
	volume = {6},
	issn = {0899-7667},
	url = {http://dx.doi.org/10.1162/neco.1994.6.5.1005},
	doi = {10.1162/neco.1994.6.5.1005},
	abstract = {Identifying and classifying action potential shapes in extracellular neural waveforms have long been the subject of research, and although several algorithms for this purpose have been successfully applied, their use has been limited by some outstanding problems. The first is how to determine shapes of the action potentials in the waveform and, second, how to decide how many shapes are distinct. A harder problem is that action potentials frequently overlap making difficult both the determination of the shapes and the classification of the spikes. In this report, a solution to each of these problems is obtained by applying Bayesian probability theory. By defining a probabilistic model of the waveform, the probability of both the form and number of spike shapes can be quantified. In addition, this framework is used to obtain an efficient algorithm for the decomposition of arbitrarily complex overlap sequences. This algorithm can extract many times more information than previous methods and facilitates the extracellular investigation of neuronal classes and of interactions within neuronal circuits.},
	number = {5},
	urldate = {2015-10-11},
	journal = {Neural Computation},
	author = {Lewicki, Michael S.},
	month = sep,
	year = {1994},
	pages = {1005--1030},
	file = {Neural Computation Snapshot:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\2SQJAZ5X\\neco.1994.6.5.html:text/html}
}

@misc{gelman_understanding_2012,
	title = {Understanding posterior p-values},
	url = {http://www.stat.columbia.edu/~gelman/research/unpublished/ppc_understand2.pdf},
	author = {Gelman, Andrew},
	month = aug,
	year = {2012}
}

@article{povey_subspace_2011,
	series = {Language and speech issues in the engineering of companionable dialogue systems},
	title = {The subspace {Gaussian} mixture model—{A} structured model for speech recognition},
	volume = {25},
	issn = {0885-2308},
	url = {http://www.sciencedirect.com/science/article/pii/S088523081000063X},
	doi = {10.1016/j.csl.2010.06.003},
	abstract = {We describe a new approach to speech recognition, in which all Hidden Markov Model (HMM) states share the same Gaussian Mixture Model (GMM) structure with the same number of Gaussians in each state. The model is defined by vectors associated with each state with a dimension of, say, 50, together with a global mapping from this vector space to the space of parameters of the GMM. This model appears to give better results than a conventional model, and the extra structure offers many new opportunities for modeling innovations while maintaining compatibility with most standard techniques.},
	number = {2},
	urldate = {2015-10-11},
	journal = {Computer Speech \& Language},
	author = {Povey, Daniel and Burget, Lukáš and Agarwal, Mohit and Akyazi, Pinar and Kai, Feng and Ghoshal, Arnab and Glembek, Ondřej and Goel, Nagendra and Karafiát, Martin and Rastrow, Ariya and Rose, Richard C. and Schwarz, Petr and Thomas, Samuel},
	month = apr,
	year = {2011},
	keywords = {Gaussian mixture model, Speech recognition, Subspace Gaussian Mixture Model},
	pages = {404--439},
	file = {ScienceDirect Snapshot:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\3GPRNC6K\\S088523081000063X.html:text/html}
}

@article{shoham_robust_2003,
	title = {Robust, automatic spike sorting using mixtures of multivariate t-distributions},
	volume = {127},
	issn = {0165-0270},
	url = {http://www.sciencedirect.com/science/article/pii/S0165027003001201},
	doi = {10.1016/S0165-0270(03)00120-1},
	abstract = {A number of recent methods developed for automatic classification of multiunit neural activity rely on a Gaussian model of the variability of individual waveforms and the statistical methods of Gaussian mixture decomposition. Recent evidence has shown that the Gaussian model does not accurately capture the multivariate statistics of the waveform samples’ distribution. We present further data demonstrating non-Gaussian statistics, and show that the multivariate t-distribution, a wide-tailed family of distributions, provides a significantly better fit to the true statistics. We introduce an adaptation of a new expectation-maximization based competitive mixture decomposition algorithm and show that it efficiently and reliably performs mixture decomposition of t-distributions. Our algorithm determines the number of units in multiunit neural recordings, even in the presence of significant noise contamination resulting from random threshold crossings and overlapping spikes.},
	number = {2},
	urldate = {2015-10-11},
	journal = {Journal of Neuroscience Methods},
	author = {Shoham, Shy and Fellows, Matthew R. and Normann, Richard A.},
	month = aug,
	year = {2003},
	keywords = {Electrode array, Expectation-maximization, Mixture models, Multi-unit recording, Multivariate t-distribution, Spike sorting, Unsupervised classification},
	pages = {111--122},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\SZPIEM3D\\Shoham et al. - 2003 - Robust, automatic spike sorting using mixtures of .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\3A9WRSDK\\S0165027003001201.html:text/html}
}

@article{brigo_lognormal-mixture_2002,
	title = {Lognormal-mixture dynamics and calibration to market volatility smiles},
	volume = {05},
	issn = {0219-0249},
	url = {http://www.worldscientific.com/doi/abs/10.1142/S0219024902001511},
	doi = {10.1142/S0219024902001511},
	abstract = {We introduce a general class of analytically tractable models for the dynamics of an asset price based on the assumption that the asset-price density is given by the mixture of known basic densities. We consider the lognormal-mixture model as a fundamental example, deriving explicit dynamics, closed form formulas for option prices and analytical approximations for the implied volatility function. We then introduce the asset-price model that is obtained by shifting the previous lognormal-mixture dynamics and investigate its analytical tractability. We finally consider a specific example of calibration to real market option data.},
	number = {04},
	urldate = {2015-10-11},
	journal = {International Journal of Theoretical and Applied Finance},
	author = {Brigo, Damiano and Mercurio, Fabio},
	month = jun,
	year = {2002},
	pages = {427--446},
	file = {Snapshot:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\MEDKJKJE\\S0219024902001511.html:text/html}
}

@incollection{fu_color_2012,
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Color {Image} {Segmentation} {Using} {Gaussian} {Mixture} {Model} and {EM} {Algorithm}},
	copyright = {©2012 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-35285-0 978-3-642-35286-7},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-35286-7_9},
	language = {en},
	number = {346},
	urldate = {2015-10-11},
	booktitle = {Multimedia and {Signal} {Processing}},
	publisher = {Springer Berlin Heidelberg},
	author = {Fu, Zhaoxia and Wang, Liming},
	editor = {Wang, Fu Lee and Lei, Jingsheng and Lau, Rynson W. H. and Zhang, Jingxin},
	year = {2012},
	keywords = {Computer Imaging, Vision, Pattern Recognition and Graphics, EM algorithm, Gaussian mixture model, Image Processing and Computer Vision, image segmentation, Information Storage and Retrieval, Multimedia Information Systems, Pattern Recognition, random variable},
	pages = {61--66},
	file = {Full Text PDF:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\PG3UCNZX\\Fu and Wang - 2012 - Color Image Segmentation Using Gaussian Mixture Mo.pdf:application/pdf;Snapshot:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\QWJCVMGA\\10.html:text/html}
}

@book{lesaffre_bayesian_2012,
	address = {Chichester, West Sussex},
	edition = {1 edition},
	title = {Bayesian {Biostatistics}},
	isbn = {978-0-470-01823-1},
	language = {English},
	publisher = {Wiley},
	author = {Lesaffre, Emmanuel and Lawson, Andrew B.},
	month = aug,
	year = {2012}
}

@article{lenk_bayesian_2000,
	title = {Bayesian inference for finite mixtures of generalized linear models with random effects},
	volume = {65},
	issn = {0033-3123, 1860-0980},
	url = {http://link.springer.com.kuleuven.ezproxy.kuleuven.be/article/10.1007/BF02294188},
	doi = {10.1007/BF02294188},
	abstract = {We present an hierarchical Bayes approach to modeling parameter heterogeneity in generalized linear models. The model assumes that there are relevant subpopulations and that within each subpopulation the individual-level regression coefficients have a multivariate normal distribution. However, class membership is not known a priori, so the heterogeneity in the regression coefficients becomes a finite mixture of normal distributions. This approach combines the flexibility of semiparametric, latent class models that assume common parameters for each sub-population and the parsimony of random effects models that assume normal distributions for the regression parameters. The number of subpopulations is selected to maximize the posterior probability of the model being true. Simulations are presented which document the performance of the methodology for synthetic data with known heterogeneity and number of sub-populations. An application is presented concerning preferences for various aspects of personal computers.},
	language = {en},
	number = {1},
	urldate = {2015-10-13},
	journal = {Psychometrika},
	author = {Lenk, Peter J. and DeSarbo, Wayne S.},
	month = mar,
	year = {2000},
	keywords = {Assessment, Testing and Evaluation, Bayesian inference, consumer behavior, finite mixtures, generalized linear models, heterogeneity, latent class analysis, Markov chain Monte Carlo, Psychometrics, Statistical Theory and Methods, Statistics for Social Science, Behavorial Science, Education, Public Policy, and Law},
	pages = {93--119},
	file = {Snapshot:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\UC64IDSH\\BF02294188.html:text/html}
}

@misc{_bayesian_????,
	type = {{SAS} support},
	title = {Bayesian {Analysis} {Using} {SAS}/{STAT} {Software}},
	url = {http://support.sas.com/rnd/app/Bayesian/index.html}
}

@book{fruhwirth-schnatter_finite_2013,
	edition = {2006 edition},
	title = {Finite {Mixture} and {Markov} {Switching} {Models}},
	language = {English},
	publisher = {Springer},
	author = {Frühwirth-Schnatter, Sylvia},
	month = apr,
	year = {2013}
}

@article{sim_evaluating_2012,
	title = {{EVALUATING} {MIXTURE} {MODELS} {FOR} {BUILDING} {RNA} {KNOWLEDGE}-{BASED} {POTENTIALS}},
	volume = {10},
	issn = {0219-7200},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4038748/},
	doi = {10.1142/S0219720012410107},
	abstract = {Ribonucleic acid (RNA) molecules play important roles in a variety of biological processes. To properly function, RNA molecules usually have to fold to specific structures, and therefore understanding RNA structure is vital in comprehending how RNA functions. One approach to understanding and predicting biomolecular structure is to use knowledge-based potentials built from experimentally determined structures. These types of potentials have been shown to be effective for predicting both protein and RNA structures, but their utility is limited by their significantly rugged nature. This ruggedness (and hence the potential's usefulness) depends heavily on the choice of bin width to sort structural information (e.g. distances) but the appropriate bin width is not known a priori. To circumvent the binning problem, we compared knowledge-based potentials built from inter-atomic distances in RNA structures using different mixture models (Kernel Density Estimation, Expectation Minimization and Dirichlet Process). We show that the smooth knowledge-based potential built from Dirichlet process is successful in selecting native-like RNA models from different sets of structural decoys with comparable efficacy to a potential developed by spline-fitting — a commonly taken approach — to binned distance histograms. The less rugged nature of our potential suggests its applicability in diverse types of structural modeling.},
	number = {2},
	urldate = {2015-10-11},
	journal = {Journal of bioinformatics and computational biology},
	author = {Sim, Adelene Y. L. and Schwander, Olivier and Levitt, Michael and Bernauer, Julie},
	month = apr,
	year = {2012},
	pmid = {22809345},
	pmcid = {PMC4038748},
	pages = {1241010},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\VUG5FWNP\\Sim et al. - 2012 - EVALUATING MIXTURE MODELS FOR BUILDING RNA KNOWLED.pdf:application/pdf}
}

@incollection{simancas-acevedo_speaker_2001,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Speaker {Recognition} {Using} {Gaussian} {Mixtures} {Models}},
	copyright = {©2001 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-42237-2 978-3-540-45723-7},
	url = {http://link.springer.com/chapter/10.1007/3-540-45723-2_34},
	language = {en},
	number = {2085},
	urldate = {2015-10-11},
	booktitle = {Bio-{Inspired} {Applications} of {Connectionism}},
	publisher = {Springer Berlin Heidelberg},
	author = {Simancas-Acevedo, Eric and Kurematsu, Akira and Miyatake, Mariko Nakano and Perez-Meana2, Hector},
	editor = {Mira, José and Prieto, Alberto},
	month = jun,
	year = {2001},
	keywords = {Algorithm Analysis and Problem Complexity, Artificial Intelligence (incl. Robotics), Computation by Abstract Devices, Computer Appl. in Life Sciences, Neurology, Neurosciences},
	pages = {287--294},
	file = {Full Text PDF:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\JM8QI3KW\\Simancas-Acevedo et al. - 2001 - Speaker Recognition Using Gaussian Mixtures Models.pdf:application/pdf;Snapshot:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\9XQI7XIX\\10.html:text/html}
}

@article{allenby_heterogeneity_1998,
	title = {On the {Heterogeneity} of {Demand}},
	volume = {35},
	copyright = {Copyright © 1998 American Marketing Association},
	issn = {0022-2437},
	url = {http://www.jstor.org.kuleuven.ezproxy.kuleuven.be/stable/3152035},
	doi = {10.2307/3152035},
	abstract = {Demand heterogeneity traditionally has been defined as segments of consumers that are homogeneous with regard to the benefits they seek or in their response to marketing programs (e.g., product offering, price discounts). Although it often is acknowledged that truly homogeneous segments of consumers do not exist, the approximation is assumed to be sufficiently accurate to provide a reasonable basis for the development of marketing strategy. In this article, the authors provide evidence that the homogeneous segment assumption might not be reasonable. By using a normal component mixture model that nests other, more commonly used models of heterogeneity, the authors find that the within-component heterogeneity remains substantial, even when multiple components are present. Predictive tests substantiate their finding of large within-component heterogeneity.},
	number = {3},
	urldate = {2015-10-13},
	journal = {Journal of Marketing Research},
	author = {Allenby, Greg M. and Arora, Neeraj and Ginter, James L.},
	month = aug,
	year = {1998},
	pages = {384--389},
	file = {JSTOR Full Text PDF:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\JE5FGB29\\Allenby et al. - 1998 - On the Heterogeneity of Demand.pdf:application/pdf}
}

@misc{_how_????-1,
	title = {How does function approximation in {Neural} network really works? - {Stack} {Overflow}},
	shorttitle = {How does function approximation in {Neural} network really works?},
	url = {http://stackoverflow.com/questions/ask},
	urldate = {2015-12-16},
	file = {Snapshot:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\Q3N23RIW\\How does function approximation in Neural network .html:text/html}
}

@article{ming-hsuan_yang_gaussian_1998,
	title = {Gaussian {Mixture} {Model} for {Human} {Skin} {Color} and {Its} {Applications} in {Image} and {Video} {Databases}},
	volume = {3656},
	issn = {0277-786X},
	doi = {10.1117/12.333865},
	journal = {Proc SPIE},
	author = {Ming-hsuan Yang, Narendra Ahuja},
	year = {1998},
	file = {Gaussian Mixture Model for Human Skin Color and Its Applications in Image and Video Databases - ResearchGate:C\:\\Users\\Anirudh\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eq7lz3kh.default\\zotero\\storage\\45IQPQ2U\\2654868_Gaussian_Mixture_Model_for_Human_Skin_Color_and_Its_Applications_in_Image_and_Video_Dat.html:text/html}
}