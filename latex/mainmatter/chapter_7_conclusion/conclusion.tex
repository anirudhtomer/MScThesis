% !TEX root =  ../../thesis.tex

\chapter{Conclusion}
\label{ch : conclusion}

As part of this thesis we evaluated the efficacy of DIC, Marginal likelihood and Posterior predictive checks for selecting the right number of components in the mixture distribution of random effects for a Bayesian heterogeneity model. We first gave the various definitions of DIC based on observed data likelihood, complete data likelihood and conditional data likelihood. We found that $\text{DIC}_4$ which was a complete DIC was the most reliable among the various definitions of the DIC's. This result also matched the findings of \citet{celeux_deviance_2006}. We also found that when the components are not well separated or if the number of subjects are less then $\text{DIC}_1$, $\text{DIC}_2$ and $\text{DIC}_3$ may not discern among the various models much and may also lead to the choice of underfitted models. They can also be used alongside $\text{DIC}_4$ when the components are well separated. We also confirmed the suggestion of \citet{fruhwirth-schnatter_finite_2013} that in cases where components are not well separated, to avoid sampling of empty components one may have to use a Dirichlet prior with slightly large values for the hyperparameter.\\

Secondly, we found that Bayes Factor via Chib's approximation was not a reliable method to detect the number of components even when the chains are converged. To use Chib's approximation one has to put constraints on the ordering of the components in the MCMC simulations, otherwise while doing chib's approximation one may get further MCMC chains with a different ordering of components. This can result into very large Bayes factor estimates.\\

For posterior predictive checks we employed the mixed predictive check technique suggested by \citet{marshall_approximate_2003} and found that overfitting models can be detected easily by exploiting non identifiability due to empty components. Empty components have posterior estimates sampled from the priors, thus giving estimates which do not support the data. More specifically we obtained right skewed distribution for the test statistic in case of the overfitted models. However because the nearly components have very small weights, the posterior predictive check requires a very large sample size. We also found that it was difficult to detect models with less number of components in the mixture because such models also gave a very good fit to the data. Having said that, in case the number of components are fitted correctly, but the posterior estimates are poor then the poor model fit can still be detected via PPC. This was especially observed in the case of using uniform prior for correlation and inverse gamma priors for random component variances, because the random component variances were underestimated.\\

Lastly, we applied the Bayesian heterogeneity model to the blood donor data set and found a mixture of 2 components to be ideal for the distribution of random effects. This was in contrast with the number of components proposed by \citet{nasserinejad_prevalence_2015} using growth mixture models. It is however interesting to note that the components we found were a subset of the components proposed by \citet{nasserinejad_prevalence_2015}. More specifically the two components that we observed differed in a way such that the subgroup of subjects with higher baseline Hemoglobin level also had a rapid decrease in Hemoglobin level with number of donations.