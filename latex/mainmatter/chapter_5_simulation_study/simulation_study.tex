% !TEX root =  ../../thesis.tex

\chapter{Simulation study}
\label{ch : simulation_study}

In this chapter we share the results from the simulation study we performed to check the efficacy of the model selection criteria described in Chapter \ref{ch : model_selection}. We implemented the Bayesian heterogeneity model using the R package R2jags \citep{su_r2jags:_2015} and analyzed the MCMC chains using the R package ggmcmc \citep{marin_ggmcmc:_2016}. For the calculation of marginal likelihood we required the density function of Wishart distribution, which was available in two packages, namely MCMCpack and mixAK. There were inconsistencies in the results from the two implementations and we eventually used mixAK \citep{komarek_mixak:_2015} as the MCMCpack package produced density function value to be $\infty$ in some cases.

\section{Data sets for simulation study}
The data sets we simulated were motivated by the study on predicting Zebu cow's weights in sub Saharan Africa \citep{lesosky_live_2012}. We assumed our response to be the weight of the Zebu cows. The predictors we considered were hypothetical, namely gender of a cattle (Male/Female), birth year of the cattle (1996/1997), age of the cattle at the first measurement and the time at which measurement was taken. The measurements of the cows were done at 10 different equally spaced time intervals. We further added subject specific random intercept and random slope effect to each response so that the repeated measurements for a given cow were correlated. Simultaneously we made sure that these cow specific random effects were mixture distributed. We will refer to the cows as subjects here forth.

\subsection{Description of each data set}
\label{subsec : ds_description}
Our aim was to create data sets differing in number of mixture components for random effects, number of subjects, separation of mixture components and number of subjects per component. To analyze the efficacy of model selection criteria under these different scenarios we created multiple data sets. To get a rough idea about the random effects in each of these data sets, we first did a graphical analysis. For this purpose we first regressed the response $\boldsymbol{y}$ on the 3 predictors: age, gender and birth year of cattle using OLS (section \ref{subsec : choice_starting_values}). It is also possible to use a LMM for estimating the fixed effects. We then regressed the residuals $y_{ij} - \boldsymbol{x}_{ij}\boldsymbol{\hat{\beta}}$ on the intercept and time of measurement for every subject separately to obtain a rough estimate $\boldsymbol{\hat{b}}_i$ of the random effect of subjects. This estimator however overestimates the actual size of the random effects because the within subject variance is also included in it. It is not possible to use Empirical Bayes estimates of the random effects because they may fail to reflect the heterogeneity in the random effects population \citep{verbeke_linear_1996}. Lastly, it is important to note that fitting an incorrect mean structure can lead to a incorrect representation of the random effects distribution. For e.g. we did not include age in the mean structure for data set 2, which is described ahead, and the corresponding plot (figure \ref{fig : missing_continuous_covariate_randplot}) for random effects did not indicate any components in the mixture. 

\subsubsection{Data set 1: No mixture distribution of random effects}
\label{subsubsec : ds_simple}
The first data set we created was without a mixture of random effects. i.e. $\boldsymbol{b}_i \sim N(0, G)$. In total we generated data of 80 subjects, each having 10 repetitions. Based on the approach mentioned above, a plot of the random effect values for this data set is shown in figure \ref{fig : ds_simple_randplot}.

\subsubsection{Data set 2: 3 well separated components for the mixture of random effects}
\label{subsubsec : ds_3wellsep}
The next data set we created had 3 well separated components forming the mixture distribution of random effects. In total we generated data of 180 subjects, each having 10 repetitions. A plot of the rough estimates of random effect values for this data set is shown in figure \ref{fig : ds_3wellsep_randplot}.

\begin{figure}[!htb]
\centering
\captionsetup{justification=centering}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ds_simple_randplot.png}
       \caption{\label{fig : ds_simple_randplot}Data set 1}
	\end{subfigure}    
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/missing_continuous_covariate_randplot.png}
       \caption{\label{fig : missing_continuous_covariate_randplot} Data set 2: Missing covariate age}
	\end{subfigure}     
\caption{\label{fig : ds_simple_n_3wellsep}Rough estimate $\boldsymbol{\hat{b}}_i$ for random effects}
\end{figure}

\subsubsection{Data set 3: 3 well separated components but less subjects}
\label{subsubsec : ds_3wellsep_3ppg}
This data is similar to Data set 2 in all regards except for the number of subjects. We generated only 36 subjects in total in this data set. A plot of the rough estimates of random effect values for this data set is shown in figure \ref{fig : ds_3wellsep3ppg_randplot}.

\subsubsection{Data set 4: 3 fused components for the mixture of random effects}
\label{subsubsec : ds_3fused_10ppg}
In this data set we simulated the random effects from a mixture distribution which had 3 fused components. For e.g. if one sees the plot of the rough estimates of random effect values for this data set (figure \ref{fig : ds_3fused10ppg_randplot}) then it is not clear if there are more than 2 components.

\begin{figure}[!htb]
\centering
\captionsetup{justification=centering}
\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ds_3wellsep_randplot.png}
        \caption{\label{fig : ds_3wellsep_randplot}Data set 2}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ds_3wellsep3ppg_randplot.png}
       \caption{\label{fig : ds_3wellsep3ppg_randplot}Data set 3}
	\end{subfigure}    
    
\caption{\label{fig : ds_3comp_3ppgwelsep}Rough estimate $\boldsymbol{\hat{b}}_i$ for random effects}
\end{figure}

\subsubsection{Data set 5: 3 fused components but less subjects}
\label{subsubsec : ds_3fused_3ppg}
This data is similar to Data set 4 in all regards except for the number of subjects. We generated only 36 subjects in total in this data set. A plot of the rough estimates of random effect values for this data set is shown in figure \ref{fig : ds_3fused3ppg_randplot}.

\subsubsection{Data set 6: 5 well separated components}
\label{subsubsec : ds_5wellsep}
In this data set we simulated the random effects from a mixture distribution which had 5 well separated components. However this time we generated unequal number of subjects for every component. The plot of the rough estimates of random effect values for this data set is shown in figure \ref{fig : ds_5wellsep_randplot}.

\begin{figure}[!htb]
\centering
\captionsetup{justification=centering}
\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ds_3fused10ppg_randplot.png}
        \caption{\label{fig : ds_3fused10ppg_randplot}Data set 4}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ds_3fused3ppg_randplot.png}
       \caption{\label{fig : ds_3fused3ppg_randplot}Data set 5}
	\end{subfigure}    
    
\caption{\label{fig : ds_3fused10ppg_3fused3ppg}Rough estimate $\boldsymbol{\hat{b}}_i$ for random effects}
\end{figure}

\subsubsection{Data set 7: 5 fused components}
\label{subsubsec : ds_5fused}
This data is similar to Data set 6 in all regards except that the number of subjects per component are less, and the components are not so well separated. The plot of the rough estimates of random effect values for this data set is shown in figure \ref{fig : ds_5fused_randplot}.

\begin{figure}[!htb]
\centering
\captionsetup{justification=centering}
\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ds_5wellsep_randplot.png}
        \caption{\label{fig : ds_5wellsep_randplot}Data set 6}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ds_5fused_randplot.png}
        \caption{\label{fig : ds_5fused_randplot}Data set 7}
	\end{subfigure}
	\caption{Rough estimate $\boldsymbol{\hat{b}}_i$ for random effects.}
	\label{fig : ds_5wellsep_5fused}    
\end{figure}


\subsection{Running MCMC simulations}
We first discuss some of the issues we encountered while doing the MCMC simulations. The first one was label switching across the chains while calculating marginal likelihood using Chib's approximation; i.e. label 1 corresponding to component 1 in one chain and corresponding to some other component in another chain. This gave inconsistent and incorrect estimates for the various calculations we did. Although we dealt with it using the mechanisms given in section \ref{subsec : label_switching_blmm}, mechanisms such as applying an ordering constraint decreased the speed of simulations drastically. The second issue was high autocorrelation in the chains which we were able to mitigate by using hierarchical centering. Using a marginal model also mitigated the issue. However for models with overfitting mixtures, neither hierarchical centering nor using marginal model decreased the high autocorrelation.\\

Despite these taking the aforementioned measures we had to employ a thinning of 1 per 100 iterations and in some cases 1 per 200 iterations to make sure the resulting chains were not autocorrelated. Since we lacked computational resources required to run longer chains we had to be content with chains of length 1300 (after thinning). Lastly, we observed that in models where mixture of random effects were fitted with more components than needed, there was very high autocorrelation in the chain which could not be reduced despite high thinning. The convergence tests for such chains showed that the chains did not converge for the parameters of some (this varied from model to model) of the component densities. The chain corresponding to fixed effect parameters showed no sign of non convergence though. Since some of the chains were not converged, it made little sense to compare DIC and marginal likelihood based on such models with models for which the chains converged. Thus we have not presented DIC and marginal likelihood for overfitted models.

\subsection{Deviance information criteria}
\label{subsec : dic_simulation_results}
The Deviance information criteria results are based on a single chain and have been rounded to the nearest integer. Table \ref{table : ds_simple_dic} shows the values of the various deviance information criteria (section \ref{sec : dic}) applied to data set 1. Since data set 1 has no mixture of random effects, models with 2 or more components overfitted the data. As we mentioned earlier that the chains did not converge for some of the parameters in the models with more components than needed, and hence DIC is not presented for them.\\

\begin{table}[!htb]
\centering
\captionsetup{justification=centering}
\caption{DIC and $\text{p}_\text{D}$ for data set 1. True number of components = 1}
\label{table : ds_simple_dic} 
\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & $\text{DIC}_1$ & $\text{DIC}_2$  & $\text{DIC}_3$  & $\text{DIC}_4$  & $\text{DIC}_5$  & $\text{DIC}_6$  \\ \midrule
1      & 4143 & 4144 & 4143 & 5160 & 4402 & 3483 \\
\bottomrule
\end{tabular}

\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & ${\text{p}_\text{D}}_1$ & ${\text{p}_\text{D}}_2$ & ${\text{p}_\text{D}}_3$ & ${\text{p}_\text{D}}_4$ & ${\text{p}_\text{D}}_5$ & ${\text{p}_\text{D}}_6$ \\ \midrule
1      & 9    & 9    & 9    & 903  & 145  & 125  \\
\bottomrule
\end{tabular}
\end{table}

Table \ref{table : ds_3wellsep_dic} shows the values of various DIC we obtained for data set 2. One of the observations from these results is that $\text{DIC}_4$ is the most discerning among all of the DIC's. $\text{DIC}_6$ prefers model with no mixture over models with 2 or 3 components, and hence it is not reliable. The rest of the DIC select the model with the right number of components.\\

\begin{table}[!htb]
\centering
\captionsetup{justification=centering}
\caption{DIC and $\text{p}_\text{D}$ for data set 2. True number of components = 3}
\label{table : ds_3wellsep_dic} 
\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & $\text{DIC}_1$ & $\text{DIC}_2$  & $\text{DIC}_3$  & $\text{DIC}_4$  & $\text{DIC}_5$  & $\text{DIC}_6$  \\ \midrule
1 & 9966 & 9959 & 9965 & 12921 & 10531 & 7855 \\
2 & 9865 & 9849 & 9864 & 12498 & 10458 & 7860 \\
3 & 9664 & 9665 & 9663 & 11847 & 10244 & 7870 \\
\bottomrule
\end{tabular}

\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & ${\text{p}_\text{D}}_1$ & ${\text{p}_\text{D}}_2$ & ${\text{p}_\text{D}}_3$ & ${\text{p}_\text{D}}_4$ & ${\text{p}_\text{D}}_5$ & ${\text{p}_\text{D}}_6$ \\ \midrule
1 & 9 & 2 & 8 & 2670 & 279 & 269 \\
2 & 15 & -1 & 14 & 2344 & 304 & 272 \\
3 & 21 & 21 & 20 & 1933 & 331 & 282 \\
\bottomrule
\end{tabular}
\end{table}

Table \ref{table : ds_3wellsep_3ppg_dic} shows the values of the various DIC applied to the data set 3. Firstly we can see that $\text{DIC}_6$ prefers model with 2 components over a model with 3 components, which is an incorrect choice of the number of the components in mixture. $\text{DIC}_5$ exhibits the same problem and hence is not reliable. The rest of the DIC select the model with the right number of components. However, once again it is $\text{DIC}_4$ which discerns the most among the various models. The magnitudes of all of the DIC for this data set were less in comparison to DIC for data set 2 because the sample size for this data set was only 36 subjects compared to 180 subjects in the former.\\

\begin{table}[!htb]
\centering
\captionsetup{justification=centering}
\caption{DIC and $\text{p}_\text{D}$ for data set 3. True number of components = 3}
\label{table : ds_3wellsep_3ppg_dic}
\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & $\text{DIC}_1$ & $\text{DIC}_2$  & $\text{DIC}_3$  & $\text{DIC}_4$  & $\text{DIC}_5$  & $\text{DIC}_6$  \\ \midrule
1 & 2013 & 2012 & 2012 & 2611 & 2118 & 1570 \\
2 & 1989 & 1949 & 1987 & 2497 & 2013 & 1562 \\
3 & 1942 & 1942 & 1940 & 2339 & 2039 & 1571 \\
\bottomrule
\end{tabular}

\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & ${\text{p}_\text{D}}_1$ & ${\text{p}_\text{D}}_2$ & ${\text{p}_\text{D}}_3$ & ${\text{p}_\text{D}}_4$ & ${\text{p}_\text{D}}_5$ & ${\text{p}_\text{D}}_6$ \\ \midrule
1 & 8 & 7 & 7 & 545 & 52 & 45 \\
2 & 14 & -26 & 12 & 465 & -20 & 35 \\
3 & 17 & 17 & 15 & 370 & 70 & 46 \\
\bottomrule
\end{tabular}
\end{table}

Table \ref{table : ds_3fused_10ppg_dic} shows the results of applying various DIC to data set 4. So far we have observed that $\text{DIC}_1$ to $\text{DIC}_4$ can be used to detect the right number of components. From the table of DIC it is clear that $\text{DIC}_1$ to $\text{DIC}_4$ can still be used to select the right number of components, however $\text{DIC}_6$ chose model 1 over model with higher number of components. $\text{DIC}_5$ has almost the same value for model with no mixture and model with 3 components in the mixture. Thus once again both $\text{DIC}_5$ and  $\text{DIC}_6$ cannot be considered reliable. To further validate the results, we decided to decrease the number of subjects to 36.\\
 
\begin{table}[!htb]
\centering
\captionsetup{justification=centering}
\caption{DIC and $\text{p}_\text{D}$ for data set 4. True number of components = 3}
\label{table : ds_3fused_10ppg_dic}
\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & $\text{DIC}_1$ & $\text{DIC}_2$  & $\text{DIC}_3$  & $\text{DIC}_4$  & $\text{DIC}_5$  & $\text{DIC}_6$  \\ \midrule
1 & 6568 & 6566 & 6566 & 8454 & 6899 & 5197 \\
2 & 6531 & 6523 & 6530 & 8263 & 6946 & 5253 \\
3 & 6497 & 6492 & 6497 & 8017 & 6898 & 5263 \\
\bottomrule
\end{tabular}

\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & ${\text{p}_\text{D}}_1$ & ${\text{p}_\text{D}}_2$ & ${\text{p}_\text{D}}_3$ & ${\text{p}_\text{D}}_4$ & ${\text{p}_\text{D}}_5$ & ${\text{p}_\text{D}}_6$ \\ \midrule
1 & 9 & 8 & 8 & 1694 & 139 & 127 \\
2 & 14 & 7 & 13 & 1527 & 210 & 182 \\
3 & 20 & 14 & 19 & 1341 & 222 & 187 \\
\bottomrule
\end{tabular}
\end{table}

Table \ref{table : ds_3fused_3ppg_dic} shows the results of calculating DIC for models applied to data set 5. The peculiarity of this data set was that the number of subjects were less and the components were fused. Thus we observed that some of the components remained empty even when we fitted the right number of components, and the chains also did not converge for some of the component density parameters. As we discussed in section \ref{subsec : choice_priors} one could use a Dirichlet prior with slightly bigger hyperparameters to avoid empty components, although at the risk of becoming too informative. For the model with 2 components, we tried various hyperparameter values between 0 and 3 and found that increasing the hyperparameter value beyond 2.5 was not necessary as the chains were converged with a $\text{Dir}(2.5, 2.5, ..., 2.5)$ prior on weight distribution. However for a model with 3 components we had to choose a $\text{Dir}(5, 5, ..., 5)$ prior to obtain chains which were converged and had posterior component density parameter values near the actual ones. The most interesting aspect of the results was that for 4 components we could not get converged chains even when we used $\text{Dir}(20, 20, ..., 20)$ prior. We also modeled the data using smaller values for Dirichlet prior hyperparameters; for e.g. $\text{Dir}(0.1, 0.1, ..., 0.1)$ and $\text{Dir}(0.6, 0.6, ..., 0.6)$ prior were tested. However both of these priors performed as worse as the $\text{Dir}(1, 1, ..., 1)$ prior for the current data set. All other DIC's other than $\text{DIC}_5$ and $\text{DIC}_6$ select the right number of components for this data set. $\text{DIC}_4$ is once again the most discerning DIC.\\

\begin{table}[!htb]
\centering
\captionsetup{justification=centering}
\caption{DIC and $\text{p}_\text{D}$ for data set 5. True number of components = 3}
\label{table : ds_3fused_3ppg_dic}
\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & $\text{DIC}_1$ & $\text{DIC}_2$  & $\text{DIC}_3$  & $\text{DIC}_4$  & $\text{DIC}_5$  & $\text{DIC}_6$  \\ \midrule
1 & 1944 & 1943 & 1943 & 2500 & 1879 & 1364 \\
2 & 1934 & 1936 & 1936 & 2438 & 2042 & 1526 \\
3 & 1921 & 1920 & 1922 & 2350 & 2023 & 1537\\
\bottomrule
\end{tabular}

\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & ${\text{p}_\text{D}}_1$ & ${\text{p}_\text{D}}_2$ & ${\text{p}_\text{D}}_3$ & ${\text{p}_\text{D}}_4$ & ${\text{p}_\text{D}}_5$ & ${\text{p}_\text{D}}_6$ \\ \midrule
1 & 9 & 7 & 7 & 510 & -110 & -119 \\
2 & 11 & 14 & 13 & 460 & 63 & 43 \\
3 & 16 & 14 & 17 & 396 & 69 & 53 \\
\bottomrule
\end{tabular}
\end{table}

Table \ref{table : ds_5wellsep_dic} shows the results of applying DIC to the various models fitted for data set 6. $\text{DIC}_5$ and $\text{DIC}_6$ give smallest DIC for underfitted models once again. The rest of the DIC's select the model with the right number of components.\\

\begin{table}[!htb]
\centering
\captionsetup{justification=centering}
\caption{DIC and $\text{p}_\text{D}$ for data set 6. True number of components = 5}
\label{table : ds_5wellsep_dic}
\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & $\text{DIC}_1$ & $\text{DIC}_2$  & $\text{DIC}_3$  & $\text{DIC}_4$  & $\text{DIC}_5$  & $\text{DIC}_6$  \\ \midrule
1 & 8982 & 8981 & 8980 & 11847 & 9251 & 6655 \\
2 & 8829 & 8827 & 8827 & 11327 & 9293 & 6838 \\
3 & 8745 & 8742 & 8744 & 11036 & 9251 & 6895 \\
4 & 8669 & 8672 & 8677 & 10737 & 9208 & 6925 \\
5 & 8649 & 8643 & 8648 & 10601 & 9165 & 6909 \\
\bottomrule
\end{tabular}

\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & ${\text{p}_\text{D}}_1$ & ${\text{p}_\text{D}}_2$ & ${\text{p}_\text{D}}_3$ & ${\text{p}_\text{D}}_4$ & ${\text{p}_\text{D}}_5$ & ${\text{p}_\text{D}}_6$ \\ \midrule
1 & 9 & 9 & 7 & 2591 & -5 & -14 \\
2 & 14 & 13 & 12 & 2224 & 190 & 169 \\
3 & 20 & 16 & 19 & 2035 & 250 & 223 \\
4 & 19 & 23 & 27 & 1824 & 296 & 251 \\
5 & 31 & 26 & 30 & 1725 & 289 & 232 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[!htb]
\centering
\captionsetup{justification=centering}
\caption{DIC and $\text{p}_\text{D}$ for data set 7. True number of components = 5}
\label{table : ds_5fused_dic}
\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & $\text{DIC}_1$ & $\text{DIC}_2$  & $\text{DIC}_3$  & $\text{DIC}_4$  & $\text{DIC}_5$  & $\text{DIC}_6$  \\ \midrule
1 & 6708 & 6707 & 6706 & 8819 & 6977 & 5071 \\
2 & 6606 & 6605 & 6604 & 8443 & 6946 & 5135 \\
3 & 6539 & 6538 & 6537 & 8178 & 6944 & 5204 \\
4 & 6506 & 6514 & 6521 & 8078 & 6915 & 5196 \\
5 & 6505 & 6500 & 6508 & 7984 & 6896 & 5202 \\
\bottomrule
\end{tabular}

\begin{tabular}{@{}rrrrrrr@{}}
\toprule
\# Components Fitted & ${\text{p}_\text{D}}_1$ & ${\text{p}_\text{D}}_2$ & ${\text{p}_\text{D}}_3$ & ${\text{p}_\text{D}}_4$ & ${\text{p}_\text{D}}_5$ & ${\text{p}_\text{D}}_6$ \\ \midrule
1 & 9 & 8 & 7 & 1903 & 61 & 53 \\
2 & 15 & 14 & 13 & 1636 & 139 & 120 \\
3 & 21 & 20 & 19 & 1456 & 221 & 185 \\
4 & 12 & 20 & 26 & 1381 & 218 & 176 \\
5 & 26 & 22 & 29 & 1308 & 220 & 182 \\
\bottomrule
\end{tabular}
\end{table}

Table \ref{table : ds_5fused_dic} shows the results of applying DIC to the various models fitted for data set 7. Based on figure \ref{fig : ds_5fused_randplot} it is difficult to identify more than 3 components in this mixture. However once again $\text{DIC}_4$ appeared to be identifying the right number of components correctly. $\text{DIC}_2$ and $\text{DIC}_3$ do not seem to discern much among the various models, which as we saw earlier, happens when the components are fused. Interestingly $\text{DIC}_1$ selects the right model only by virtue of a difference of DIC value of 1 between model with 4 components and 5 components.\\

\subsubsection{The rule of thumb for model selection using DIC}
It is important to note that when components were fused, then even with a very large number of MCMC iterations we observed a variation of 10 to 20 in the same DIC across chains. Thus, although $\text{DIC}_3$ preferred model 5 over model 4 by a DIC difference of 13, it is highly plausible to obtain a difference of -7; i.e. Model 4 having a lower $\text{DIC}_3$ than model 5. In such a case if the classical rule of thumb of DIC difference of 5 to 10 is used to select the models then an incorrect model might get selected.

\subsection{Marginal likelihood}
\label{subsec : marginal_likelihood_simulation}
To calculate marginal likelihood for the various models we implemented Chib's approximation described in section \ref{sec : marginal_likelihood}. Table \ref{table : marginal_likelihood_results} shows the results of $\log{\hat{m}(\boldsymbol{y})}$ for the various models we fitted to data set 1 to data set 7. One can see that even among the  models which showed no sign of non convergence in the chains there is no obvious pattern visible in the results to conclude the efficacy of marginal likelihood in selection of a model. For e.g. in case of data set 6 there were 5 well separated components in the mixture distribution of random effects. When we fitted 1 to 5 components for this data set we obtained MCMC chains with good convergence. However in table \ref{table : marginal_likelihood_results} we can see that marginal likelihood prefers fitting 4 components over 5 components. For data set 3 where we had 3 well separated components but only 36 subjects in total, we can observe that marginal likelihood incorrectly prefers mixture with no component instead of the correct mixture with 3 components. Thus marginal likelihood using Chib's approximation does not seem to be a very reliable method to choose the correct Bayesian heterogeneity model.

\begin{table}[!htb]
\centering
\captionsetup{justification=centering}
\caption{$\log{\hat{m}(\boldsymbol{y})}$ for data set 1}
\label{table : marginal_likelihood_results} 
\begin{tabular}{lrrrrr}
\toprule
Fitted & 1 Comp & 2 Comp & 3 Comp & 4 Comp & 5 Comp \\\midrule
Data set 1 & -2120 & & & & \\
Data set 2 & -5019 & -4989 & -4937 & & \\
Data set 3 & -1038 & -1044 & -1042 & & \\
Data set 4 & -3317 & -3318 & -3322 & & \\
Data set 5 & -1001 & -986 & -993 & &  \\
Data set 6 & -4545 & -4492 & -4477 & -4467 & -4473\\
Data set 7 & -3397 & -3379 & -3373 & -3380 & -2749\\ \bottomrule
\end{tabular}
\end{table}

\subsection{Posterior predictive check (PPC)}
\label{subsec : ppc_simulation}
We implemented the PPC outlined in section \ref{sec : ppc} and found that it worked quite well irrespective of the size of the data set or how well separated the components were. Secondly, since the PPC we used was designed to detect non identifiability due to empty components it worked well for models which were overfitting and thus had empty components. It is important to note that for such models, the convergence diagnostics did not show any evidence against convergence of chains for fixed effect coefficients. It were only some of the component densities whose parameters which did not converge, which as we mentioned earlier, varied from model to model.\\

\begin{figure}[!htb]
\centering
\captionsetup{justification=centering}
\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ppc_5wellsep8comp.png}
        \caption{\label{fig : ppc_5wellsep8comp} \# Components fitted = 8}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ppc_5wellsep7comp.png}
          \caption{\label{fig : ppc_5wellsep7comp}\# Components fitted = 7}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ppc_5wellsep6comp.png}
          \caption{\label{fig : ppc_5wellsep6comp}\# Components fitted = 6}
	\end{subfigure}
	
	\caption{Density function of $T(\boldsymbol{\tilde{r}})$ for overfitted models applied to data set 6. The red line shows the value of the test statistic $T(\boldsymbol{r})$ based on the observed data.}
	\label{fig : ppc_5wellsepcomp_overfitted}    
\end{figure}

\begin{figure}[!htb]
\centering
\captionsetup{justification=centering}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ppc_5wellsep5comp.png}
          \caption{\label{fig : ppc_5wellsep5comp}\# Components fitted = 5}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ppc_5wellsep4comp.png}
          \caption{\label{fig : ppc_5wellsep4comp}\# Components fitted = 4}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ppc_5wellsep3comp.png}
          \caption{\label{fig : ppc_5wellsep3comp}\# Components fitted = 3}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ppc_5wellsep2comp.png}
          \caption{\label{fig : ppc_5wellsep2comp}\# Components fitted = 2}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/ppc_5wellsep1comp.png}
          \caption{\label{fig : ppc_5wellsep1comp}\# Components fitted = 1}
	\end{subfigure}
	\caption{Density function of $T(\boldsymbol{\tilde{r}})$ for under/rightly fitted models applied to data set 6. The red line shows the value of the test statistic $T(\boldsymbol{r})$ based on the observed data.}
	\label{fig : ppc_5wellsepcomp_underfitted}    
\end{figure}

We found the results of PPC to be very consistent across the various data sets and so we discuss only the results of fitting various number of components to data set 6. Figure \ref{fig : ppc_5wellsepcomp_overfitted} and figure \ref{fig : ppc_5wellsepcomp_underfitted} show the distribution of the test statistic in equation \ref{eq : ppc_test_statistic} for the various models we fitted to data set 6. It can be seen that the distribution is positively skewed whenever overfitting is present, which can be attributed to sampling from empty components as we discussed in section \ref{subsec : ppc_bhtge}. On the other hand the distribution of the test statistic is more or less the same in cases of underfitting.\\

\begin{table}[!htb]
\centering
\captionsetup{justification=centering}
\caption{PPP values for the various models fitted to data set 6.}
\label{table : ppp_value_5welsepcomp}
\begin{tabular}{@{}rrrrrrrrr@{}}
\toprule
\# Components fitted & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ \midrule
PPP Value & 0.500 & 0.500 & 0.492 & 0.500 & 0.500 & 0.581 & 0.674 & 0.775 \\ \bottomrule
\end{tabular}
\end{table}

We also calculated posterior predictive p-values for the various number of components we fitted to data set and they are presented in table \ref{table : ppp_value_5welsepcomp}. The PPP values are all equal to 0.5 for the models with underfitted mixtures. Based on the graphical PPC and these PPP values, it was not possible to choose a model among the correctly fitted and underfitted ones. On the other hand, for models with overfitted components the PPP values increase as overfitting increases.\\

We observed a more severe impact of overfitting when we used independent inverse gamma priors for the variance components of $G_k$ and uniform prior $U(-1,1)$ for correlation. To show the resulting distribution of the test statistic, we had to log transform it because otherwise the values were too large to be plotted in a single graph. For data set 2 we overfitted the mixture of random effects by using 4 components in the mixture. As shown in Figure \ref{fig : ppc_3wellsep4comp_indp_gammaprior} the log of the test statistic is inflated by a large margin, which was also discussed in section \ref{sec : ppc}. Interestingly when we fitted the right number of components the test statistic was not inflated, yet from the distribution of the test statistic it was clear that the model was not fitting well to the data (Figure \ref{fig : ppc_3wellsep3comp_indp_gammaprior}). The PPP-value we obtained for this model was equal to 1. To diagnose this problem we checked the posterior distribution of variance covariance matrices of random effects and found that the posterior variances of random effects were underestimating the sample data's variance covariance of the random effects. This shows that the test statistic can not only be be used to detect models with overfitting mixtures, but even an overall bad model fit despite having the right number of components in the mixture, can be detected.\\

\begin{figure}[!htb]
	\centering
	\captionsetup{justification=centering}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/indpGammaPrior_ppc_3wellsep4comp.png}
        \caption{\label{fig : ppc_3wellsep4comp_indp_gammaprior}4 components fitted for data set 2. log scale is used.}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{mainmatter/chapter_5_simulation_study/indpGammaPrior_ppc_3wellsep3comp.png}
        \caption{\label{fig : ppc_3wellsep3comp_indp_gammaprior}3 components fitted for data set 2}
	\end{subfigure}
	\caption{PDF function of $T(\boldsymbol{\tilde{r}})$ estimated using KDE. The red line shows the value of the test statistic $T(\boldsymbol{r})$ based on the observed data. Independent inverse gamma priors for variance of random effects and uniform prior for correlation is used.}
	\label{fig : ppc_3wellsepcomp_indp_gammaprior}
\end{figure}